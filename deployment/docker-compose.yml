version: '3.3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    restart: always
    ports:
      - '2181'
    hostname: zookeeper
    volumes:
      - /home/phamminhtan/zookeeper/data:/opt/zookeeper-3.4.13/data
  kafka:
    image: wurstmeister/kafka
    restart: always
    command: [start-kafka.sh]
    ports:
      - '9092:9092'
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: 'events:1:1' # topic:partition:replicas
      KAFKA_ADVERTISED_HOST_NAME: messager.eastus2.cloudapp.azure.com
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://messager.eastus2.cloudapp.azure.com:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/kafka-logs
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/phamminhtan/kafka:/kafka/kafka-logs
    depends_on:
      - 'zookeeper'
  db:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: 'events'
      # So you don't have to use root, but you can if you like
      MYSQL_USER: 'phamminhtan'
      # You can use whatever password you like
      MYSQL_PASSWORD: 'Password'
      # Password for root access
      MYSQL_ROOT_PASSWORD: 'Password'
    ports:
      # <Port exposed> : < MySQL Port running inside container>
      - '3306:3306'
    expose:
      # Opens port 3306 on the container
      - '3306'
    # Where our data will be persisted
    volumes:
      - my-db:/var/lib/mysql
  receiver:
    image: receiver
    restart: always
    ports:
      - '8080'
    networks:
      - 'api.network'
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/phamminhtan/config/receiver:/config
      - /home/phamminhtan/logs:/logs
    depends_on:
      - 'kafka'
  storage:
    image: storage
    restart: always
    ports:
      - '8090'
    networks:
      - 'api.network'
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/phamminhtan/config/storage:/config
      - /home/phamminhtan/logs:/logs
    depends_on:
      - 'kafka'
      - 'db'
  processing:
    image: processing
    restart: always
    ports:
      - '8100'
    networks:
      - 'api.network'
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/phamminhtan/config/processing:/config
      - /home/phamminhtan/logs:/logs
      - processing-db:/data
    depends_on:
      - 'storage'
  audit_log:
    image: audit_log
    restart: always
    ports:
      - '8110'
    networks:
      - 'api.network'
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/phamminhtan/config/audit_log:/config
      - /home/phamminhtan/logs:/logs
    depends_on:
      - 'kafka'
  health:
    image: health:healthapp
    restart: always
    ports:
      - '8120:8120'
    network_mode: 'host'
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/phamminhtan/config/health:/config
      - /home/phamminhtan/logs:/logs
      - health-db:/data
    depends_on:
      - 'receiver'
      - 'storage'
      - 'processing'
      - 'audit_log'
  dashboard:
    image: dashboard
    restart: always
    ports:
      - '3000'
    networks:
      - 'api.network'
    depends_on:
      - 'processing'
      - 'audit_log'
  nginx:
    image: nginx:latest
    # Connects the conf file of the container to the conf file in our folder
    volumes:
      - /home/phamminhtan/nginx/nginx.conf:/etc/nginx/nginx.conf
    # It will start up the nginx only when all api containers have started
    depends_on:
      - 'receiver'
      - 'storage'
      - 'processing'
      - 'audit_log'
      - 'dashboard'
    # Connects the port 80 of the nginx container to localhost:80 or localhost
    ports:
      - '80:80'
    networks:
      - 'api.network'
# Names our volume
volumes:
  my-db:
  processing-db:
  health-db:
#Network
networks:
  api.network:
